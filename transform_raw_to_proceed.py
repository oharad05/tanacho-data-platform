#!/usr/bin/env python3
"""
raw/ â†’ proceed/ å¤‰æ›å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Excel(.xlsx)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVã«å¤‰æ›ã—ã€ã‚«ãƒ©ãƒ åã‚’ãƒžãƒƒãƒ”ãƒ³ã‚°ã—ã¦
BigQueryé€£æºç”¨ã®ãƒ‡ãƒ¼ã‚¿ã«æ•´å½¢ã™ã‚‹
"""

import os
import io
import re
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Optional, Any
from google.cloud import storage
from pathlib import Path

# å›ºå®šå€¤è¨­å®š
PROJECT_ID = "data-platform-prod-475201"
LANDING_BUCKET = "data-platform-landing-prod"
COLUMNS_PATH = "columns"  # ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚«ãƒ©ãƒ å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

def load_column_mapping(table_name: str) -> Dict[str, Dict[str, str]]:
    """
    ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°å®šç¾©ã‚’èª­ã¿è¾¼ã¿
    
    Args:
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆä¾‹: sales_target_and_achievementsï¼‰
    
    Returns:
        {æ—¥æœ¬èªžã‚«ãƒ©ãƒ å: {"en_name": è‹±èªžå, "type": ãƒ‡ãƒ¼ã‚¿åž‹}}
    """
    mapping_file = f"{COLUMNS_PATH}/{table_name}.csv"
    if not os.path.exists(mapping_file):
        print(f"âš ï¸  ãƒžãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {mapping_file}")
        return {}
    
    df = pd.read_csv(mapping_file)
    mapping = {}
    for _, row in df.iterrows():
        mapping[row['jp_name']] = {
            'en_name': row['en_name'],
            'type': row['type']
        }
    return mapping

def convert_date_format(value: Any, date_type: str, column_name: str = '') -> str:
    """
    æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã®å¤‰æ›
    
    Args:
        value: å¤‰æ›å¯¾è±¡ã®å€¤
        date_type: DATE or DATETIME
        column_name: ã‚«ãƒ©ãƒ åï¼ˆç‰¹æ®Šå‡¦ç†ç”¨ï¼‰
    
    Returns:
        å¤‰æ›å¾Œã®æ—¥ä»˜æ–‡å­—åˆ—
    """
    if pd.isna(value) or value == '' or value is None:
        return ''
    
    # æ•°å€¤ã®å ´åˆã®å‡¦ç†
    if isinstance(value, (int, float)):
        # Excelã®ã‚·ãƒªã‚¢ãƒ«æ—¥ä»˜ã®å ´åˆï¼ˆ1900å¹´1æœˆ1æ—¥ã‹ã‚‰ã®æ—¥æ•°ï¼‰
        if value > 0 and value < 100000:
            try:
                # Excelæ—¥ä»˜ã®èµ·ç‚¹ã¯1899-12-30
                excel_base = pd.Timestamp('1899-12-30')
                dt = excel_base + pd.Timedelta(days=int(value))
                if date_type == 'DATETIME':
                    return dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                pass
        
        # Unixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆãƒŠãƒŽç§’ï¼‰ã®å ´åˆ
        elif value > 1e15:
            try:
                # ãƒŠãƒŽç§’ã‚’Datetimeã«å¤‰æ›
                dt = pd.to_datetime(value, unit='ns')
                if date_type == 'DATETIME':
                    return dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                pass
    
    # æ–‡å­—åˆ—ã«å¤‰æ›
    value_str = str(value)
    
    # internal_interestã®å¹´æœˆã‚«ãƒ©ãƒ ç‰¹æ®Šå‡¦ç†ï¼ˆä¾‹: "2025å¹´9æœˆ" â†’ "2025-09-01"ï¼‰
    if column_name == 'å¹´æœˆ' and 'å¹´' in value_str and 'æœˆ' in value_str:
        try:
            # "2025å¹´9æœˆ" ã®ã‚ˆã†ãªå½¢å¼ã‹ã‚‰å¹´æœˆã‚’æŠ½å‡º
            match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ', value_str)
            if match:
                year = match.group(1)
                month = match.group(2).zfill(2)
                return f"{year}-{month}-01"
        except:
            pass
    
    # profit_plan_termã®æœŸé–“ã‚«ãƒ©ãƒ ç‰¹æ®Šå‡¦ç†ï¼ˆåŒæ§˜ï¼‰
    if column_name == 'æœŸé–“' and 'å¹´' in value_str and 'æœˆ' in value_str:
        try:
            match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ', value_str)
            if match:
                year = match.group(1)
                month = match.group(2).zfill(2)
                return f"{year}-{month}-01"
        except:
            pass
    
    # DATEåž‹ã®å‡¦ç†
    if date_type == 'DATE':
        # YYYY/MMå½¢å¼ã®å ´åˆã€1æ—¥ã‚’è¿½åŠ 
        if re.match(r'^\d{4}/\d{1,2}$', value_str):
            try:
                dt = pd.to_datetime(value_str + '/01', format='%Y/%m/%d')
                return dt.strftime('%Y-%m-%d')
            except:
                pass
        
        # ãã®ä»–ã®æ—¥ä»˜å½¢å¼
        try:
            dt = pd.to_datetime(value_str)
            return dt.strftime('%Y-%m-%d')
        except:
            print(f"âš ï¸  æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {value_str}")
            return value_str
    
    # DATETIMEåž‹ã®å‡¦ç†
    elif date_type == 'DATETIME':
        try:
            dt = pd.to_datetime(value_str)
            return dt.strftime('%Y-%m-%d %H:%M:%S')
        except:
            print(f"âš ï¸  æ—¥æ™‚å¤‰æ›ã‚¨ãƒ©ãƒ¼: {value_str}")
            return value_str
    
    return value_str

def apply_data_type_conversion(df: pd.DataFrame, column_mapping: Dict) -> pd.DataFrame:
    """
    ãƒ‡ãƒ¼ã‚¿åž‹å¤‰æ›ã‚’é©ç”¨
    
    Args:
        df: å¤‰æ›å¯¾è±¡ã®DataFrame
        column_mapping: ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°å®šç¾©
    
    Returns:
        åž‹å¤‰æ›å¾Œã®DataFrame
    """
    df = df.copy()
    
    for col in df.columns:
        if col not in column_mapping:
            continue
        
        data_type = column_mapping[col]['type']
        
        # DATE/DATETIMEåž‹
        if data_type in ['DATE', 'DATETIME']:
            # datetime64åž‹ã®å ´åˆã¯ç›´æŽ¥å¤‰æ›
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                if data_type == 'DATE':
                    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')
                else:
                    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d %H:%M:%S')
            else:
                df[col] = df[col].apply(lambda x: convert_date_format(x, data_type, col))
        
        # INT64åž‹
        elif data_type == 'INT64':
            # ç©ºæ–‡å­—ã‚„NaNã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«nullable integerã‚’ä½¿ç”¨
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].astype('Int64')
        
        # NUMERICåž‹
        elif data_type == 'NUMERIC':
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # STRINGåž‹
        elif data_type == 'STRING':
            df[col] = df[col].fillna('')
            df[col] = df[col].astype(str)
            # 'nan'æ–‡å­—åˆ—ã‚’ç©ºæ–‡å­—ã«ç½®æ›
            df[col] = df[col].replace('nan', '')
    
    return df

def rename_columns(df: pd.DataFrame, column_mapping: Dict) -> pd.DataFrame:
    """
    ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªžã‹ã‚‰è‹±èªžã«å¤‰æ›
    
    Args:
        df: å¤‰æ›å¯¾è±¡ã®DataFrame
        column_mapping: ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°å®šç¾©
    
    Returns:
        ã‚«ãƒ©ãƒ åå¤‰æ›å¾Œã®DataFrame
    """
    rename_dict = {}
    
    for jp_col in df.columns:
        if jp_col in column_mapping:
            en_col = column_mapping[jp_col]['en_name']
            rename_dict[jp_col] = en_col
        else:
            print(f"âš ï¸  ãƒžãƒƒãƒ”ãƒ³ã‚°æœªå®šç¾©ã®ã‚«ãƒ©ãƒ : {jp_col}")
            # ãƒžãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯å…ƒã®åå‰ã‚’ä¿æŒ
            rename_dict[jp_col] = jp_col
    
    return df.rename(columns=rename_dict)

def transform_excel_to_csv(
    input_path: str,
    output_path: str,
    table_name: str,
    sheet_name: Optional[str] = None
) -> bool:
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§CSVã«å¤‰æ›
    
    Args:
        input_path: å…¥åŠ›Excelãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_path: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
        sheet_name: ã‚·ãƒ¼ãƒˆåï¼ˆçœç•¥æ™‚ã¯æœ€åˆã®ã‚·ãƒ¼ãƒˆï¼‰
    
    Returns:
        æˆåŠŸæ™‚True
    """
    try:
        print(f"\nðŸ“„ å‡¦ç†ä¸­: {table_name}")
        print(f"   å…¥åŠ›: {input_path}")
        
        # ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿
        column_mapping = load_column_mapping(table_name)
        if not column_mapping:
            print(f"âŒ ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_name}")
            return False
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        if sheet_name:
            df = pd.read_excel(input_path, sheet_name=sheet_name)
        else:
            # sheet_nameã‚’æŒ‡å®šã—ãªã„å ´åˆã€æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
            df = pd.read_excel(input_path)
        
        # DataFrameãŒè¾žæ›¸ã¨ã—ã¦è¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if isinstance(df, dict):
            # æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’å–å¾—
            df = list(df.values())[0]
        
        # ã‚«ãƒ©ãƒ åã®æ”¹è¡Œã‚’é™¤åŽ»
        df.columns = [col.replace('\n', '') if isinstance(col, str) else col for col in df.columns]
        
        print(f"   ãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
        
        # æ—¥æœ¬èªžã‚«ãƒ©ãƒ åã‚’è‹±èªžã«å¤‰æ›ï¼ˆåž‹å¤‰æ›å‰ã«å®Ÿæ–½ï¼‰
        jp_column_mapping = {jp: info for jp, info in column_mapping.items()}
        
        # æ—¥ä»˜åˆ—ã®äº‹å‰å‡¦ç†ï¼ˆdatetime64åž‹ã®å‡¦ç†ï¼‰
        for jp_col, info in jp_column_mapping.items():
            if jp_col in df.columns and info['type'] in ['DATE', 'DATETIME']:
                if pd.api.types.is_datetime64_any_dtype(df[jp_col]):
                    if info['type'] == 'DATE':
                        df[jp_col] = df[jp_col].dt.strftime('%Y-%m-%d')
                    else:
                        df[jp_col] = df[jp_col].dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # ãƒ‡ãƒ¼ã‚¿åž‹å¤‰æ›
        df = apply_data_type_conversion(df, jp_column_mapping)
        
        # ã‚«ãƒ©ãƒ åå¤‰æ›
        df = rename_columns(df, jp_column_mapping)
        
        # CSVå‡ºåŠ›
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"   å‡ºåŠ›: {output_path}")
        print(f"âœ… å¤‰æ›å®Œäº†: {table_name}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
        import traceback
        traceback.print_exc()
        return False

def process_gcs_files(yyyymm: str):
    """
    GCSä¸Šã®raw/ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã—ã¦proceed/ã«ä¿å­˜
    
    Args:
        yyyymm: å¯¾è±¡å¹´æœˆï¼ˆä¾‹: 202509ï¼‰
    """
    print("=" * 60)
    print(f"raw/ â†’ proceed/ å¤‰æ›å‡¦ç†")
    print(f"å¯¾è±¡å¹´æœˆ: {yyyymm}")
    print(f"ãƒã‚±ãƒƒãƒˆ: {LANDING_BUCKET}")
    print("=" * 60)
    
    # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = storage.Client()
    bucket = client.bucket(LANDING_BUCKET)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒªã‚¹ãƒˆï¼ˆãƒžãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
    tables = [
        "sales_target_and_achievements",
        "billing_balance",
        "ledger_income",
        "department_summary",
        "internal_interest",
        "profit_plan_term",
        "ledger_loss"
    ]
    
    success_count = 0
    error_count = 0
    
    for table_name in tables:
        try:
            # GCSãƒ‘ã‚¹
            raw_path = f"raw/{yyyymm}/{table_name}.xlsx"
            proceed_path = f"proceed/{yyyymm}/{table_name}.csv"
            
            # rawãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            raw_blob = bucket.blob(raw_path)
            if not raw_blob.exists():
                print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: gs://{LANDING_BUCKET}/{raw_path}")
                error_count += 1
                continue
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            temp_excel = f"/tmp/{table_name}.xlsx"
            temp_csv = f"/tmp/{table_name}.csv"
            
            raw_blob.download_to_filename(temp_excel)
            
            # å¤‰æ›å‡¦ç†
            if transform_excel_to_csv(temp_excel, temp_csv, table_name):
                # proceedã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                proceed_blob = bucket.blob(proceed_path)
                proceed_blob.upload_from_filename(temp_csv)
                print(f"   â†’ gs://{LANDING_BUCKET}/{proceed_path}")
                success_count += 1
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.remove(temp_excel)
                os.remove(temp_csv)
            else:
                error_count += 1
                
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
            error_count += 1
    
    print("=" * 60)
    print(f"å‡¦ç†å®Œäº†: æˆåŠŸ {success_count} / ã‚¨ãƒ©ãƒ¼ {error_count}")
    print("=" * 60)

def process_local_files(yyyymm: str):
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›
    
    Args:
        yyyymm: å¯¾è±¡å¹´æœˆ
    """
    print("=" * 60)
    print(f"ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ›ãƒ†ã‚¹ãƒˆ")
    print(f"å¯¾è±¡å¹´æœˆ: {yyyymm}")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    if os.path.exists("/tmp/sample.xlsx"):
        output_path = "/tmp/sample_proceed.csv"
        if transform_excel_to_csv(
            "/tmp/sample.xlsx",
            output_path,
            "sales_target_and_achievements"
        ):
            # çµæžœç¢ºèª
            df = pd.read_csv(output_path)
            print("\nå¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
            print(f"ã‚«ãƒ©ãƒ : {list(df.columns)[:5]}...")
            print(f"ãƒ‡ãƒ¼ã‚¿åž‹: {df.dtypes.head()}")
            print(f"æœ€åˆã®è¡Œ: {df.iloc[0].to_dict() if len(df) > 0 else 'No data'}")

if __name__ == "__main__":
    import sys
    
    # ã‚³ãƒžãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰å¹´æœˆã‚’å–å¾—
    yyyymm = sys.argv[1] if len(sys.argv) > 1 else "202509"
    
    # GCSå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã¨ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ
    if len(sys.argv) > 2 and sys.argv[2] == "--local":
        process_local_files(yyyymm)
    else:
        process_gcs_files(yyyymm)