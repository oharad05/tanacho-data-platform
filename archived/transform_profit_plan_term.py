#!/usr/bin/env python3
"""
profit_plan_termå°‚ç”¨ã®Excelâ†’CSVå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os, io
import pandas as pd
import numpy as np
from google.cloud import storage, bigquery

PROJECT_ID = "data-platform-prod-475201"
DATASET_ID = "corporate_data"
LANDING_BUCKET = "data-platform-landing-prod"
COLUMNS_PATH = "config/columns"

def load_column_mapping(storage_client, table_name):
    """ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°å®šç¾©ã‚’èª­ã¿è¾¼ã¿"""
    bucket = storage_client.bucket(LANDING_BUCKET)
    mapping_blob = bucket.blob(f"{COLUMNS_PATH}/{table_name}.csv")

    if not mapping_blob.exists():
        print(f"âŒ ãƒžãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_name}.csv")
        return {}

    csv_data = mapping_blob.download_as_bytes()
    df = pd.read_csv(io.BytesIO(csv_data))

    mapping = {}
    for _, row in df.iterrows():
        mapping[row['jp_name']] = {
            'en_name': row['en_name'],
            'type': row['type']
        }
    return mapping

def convert_date_format(value, date_type, column_name=''):
    """æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã®å¤‰æ›"""
    if pd.isna(value) or value == '' or value is None:
        return ''

    # pandas Timestampåž‹ã®å ´åˆ
    if isinstance(value, pd.Timestamp):
        if date_type == 'DATETIME':
            return value.strftime('%Y-%m-%d %H:%M:%S')
        else:
            return value.strftime('%Y-%m-%d')

    # æ•°å€¤ã®å ´åˆã®å‡¦ç†
    if isinstance(value, (int, float, np.integer, np.floating)):
        # ãƒŠãƒŽç§’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆ1e15ä»¥ä¸Šï¼‰
        if value >= 1e15:
            try:
                dt = pd.to_datetime(value, unit='ns')
                if date_type == 'DATETIME':
                    return dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                pass

        # Excelã®ã‚·ãƒªã‚¢ãƒ«æ—¥ä»˜
        elif value > 0 and value < 100000:
            try:
                excel_base = pd.Timestamp('1899-12-30')
                dt = excel_base + pd.Timedelta(days=int(value))
                if date_type == 'DATETIME':
                    return dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                pass

    # æ–‡å­—åˆ—ã«å¤‰æ›
    value_str = str(value)

    # ã€Œå¹´æœˆã€ç‰¹æ®Šå‡¦ç†ï¼ˆä¾‹: "2025å¹´9æœˆ" â†’ "2025-09-01"ï¼‰
    if 'å¹´' in value_str and 'æœˆ' in value_str:
        import re
        try:
            match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ', value_str)
            if match:
                year = match.group(1)
                month = match.group(2).zfill(2)
                return f"{year}-{month}-01"
        except:
            pass

    # DATEåž‹ã®å‡¦ç†
    if date_type == 'DATE':
        # YYYY/MMå½¢å¼ã®å ´åˆã€1æ—¥ã‚’è¿½åŠ 
        import re
        if re.match(r'^\d{4}/\d{1,2}$', value_str):
            try:
                dt = pd.to_datetime(value_str + '/01', format='%Y/%m/%d')
                return dt.strftime('%Y-%m-%d')
            except:
                pass

        try:
            dt = pd.to_datetime(value_str)
            return dt.strftime('%Y-%m-%d')
        except:
            print(f"âš ï¸  æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {value_str}")
            return value_str

    # DATETIMEåž‹ã®å‡¦ç†
    elif date_type == 'DATETIME':
        try:
            dt = pd.to_datetime(value_str)
            return dt.strftime('%Y-%m-%d %H:%M:%S')
        except:
            print(f"âš ï¸  æ—¥æ™‚å¤‰æ›ã‚¨ãƒ©ãƒ¼: {value_str}")
            return value_str

    return value_str

def apply_data_type_conversion(df, column_mapping):
    """ãƒ‡ãƒ¼ã‚¿åž‹å¤‰æ›ã‚’é©ç”¨"""
    df = df.copy()

    for col in df.columns:
        if col not in column_mapping:
            continue

        data_type = column_mapping[col]['type']

        # DATE/DATETIMEåž‹
        if data_type in ['DATE', 'DATETIME']:
            # ã™ã¹ã¦ã®ã‚±ãƒ¼ã‚¹ã§æ–‡å­—åˆ—ã«å¤‰æ›
            df[col] = df[col].apply(lambda x: convert_date_format(x, data_type, col) if pd.notna(x) and x != '' else '')

        # INT64åž‹
        elif data_type == 'INT64':
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].astype('Int64')

        # NUMERICåž‹
        elif data_type == 'NUMERIC':
            df[col] = pd.to_numeric(df[col], errors='coerce')

        # STRINGåž‹
        elif data_type == 'STRING':
            df[col] = df[col].fillna('')
            df[col] = df[col].astype(str)
            df[col] = df[col].replace('nan', '')

    return df

def rename_columns(df, column_mapping):
    """ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªžã‹ã‚‰è‹±èªžã«å¤‰æ›"""
    rename_dict = {}

    for jp_col in df.columns:
        if jp_col in column_mapping:
            en_col = column_mapping[jp_col]['en_name']
            rename_dict[jp_col] = en_col
        else:
            print(f"âš ï¸  ãƒžãƒƒãƒ”ãƒ³ã‚°æœªå®šç¾©ã®ã‚«ãƒ©ãƒ : {jp_col}")
            rename_dict[jp_col] = jp_col

    return df.rename(columns=rename_dict)

def transform_excel_to_csv(storage_client, table_name, yyyymm):
    """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§CSVã«å¤‰æ›"""
    try:
        print(f"\nðŸ“„ å‡¦ç†ä¸­: {table_name}")

        bucket = storage_client.bucket(LANDING_BUCKET)

        # raw/ ã‹ã‚‰èª­ã¿è¾¼ã¿
        raw_path = f"raw/{yyyymm}/{table_name}.xlsx"
        raw_blob = bucket.blob(raw_path)

        if not raw_blob.exists():
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: gs://{LANDING_BUCKET}/{raw_path}")
            return False

        # ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿
        column_mapping = load_column_mapping(storage_client, table_name)
        if not column_mapping:
            print(f"âŒ ã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_name}")
            return False

        # Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        excel_bytes = raw_blob.download_as_bytes()

        # profit_plan_termã®å ´åˆã¯ã€Œæ±äº¬æ”¯åº—ç›®æ¨™103æœŸã€ã‚·ãƒ¼ãƒˆã®ã¿ã‚’èª­ã¿è¾¼ã‚€
        if table_name == "profit_plan_term":
            df = pd.read_excel(io.BytesIO(excel_bytes), sheet_name='æ±äº¬æ”¯åº—ç›®æ¨™103æœŸ')
            print(f"   ã‚·ãƒ¼ãƒˆæŒ‡å®š: æ±äº¬æ”¯åº—ç›®æ¨™103æœŸ")
        else:
            df = pd.read_excel(io.BytesIO(excel_bytes))

        # ã‚«ãƒ©ãƒ åã®æ”¹è¡Œã‚’é™¤åŽ»
        df.columns = [col.replace('\n', '') if isinstance(col, str) else col for col in df.columns]

        print(f"   ãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")

        # æ—¥æœ¬èªžã‚«ãƒ©ãƒ åã‚’è‹±èªžã«å¤‰æ›ï¼ˆåž‹å¤‰æ›å‰ï¼‰
        jp_column_mapping = {jp: info for jp, info in column_mapping.items()}

        # æ—¥ä»˜åˆ—ã®äº‹å‰å‡¦ç†
        for jp_col, info in jp_column_mapping.items():
            if jp_col in df.columns and info['type'] in ['DATE', 'DATETIME']:
                if pd.api.types.is_datetime64_any_dtype(df[jp_col]):
                    if info['type'] == 'DATE':
                        df[jp_col] = df[jp_col].dt.strftime('%Y-%m-%d')
                    else:
                        df[jp_col] = df[jp_col].dt.strftime('%Y-%m-%d %H:%M:%S')

        # ãƒ‡ãƒ¼ã‚¿åž‹å¤‰æ›
        df = apply_data_type_conversion(df, jp_column_mapping)

        # ã‚«ãƒ©ãƒ åå¤‰æ›
        df = rename_columns(df, jp_column_mapping)

        # CSVå‡ºåŠ›å‰ã®æœ€çµ‚ç¢ºèªï¼šDATE/DATETIMEåˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        for jp_col, info in column_mapping.items():
            en_col = info['en_name']
            if en_col in df.columns:
                data_type = info['type']
                if data_type == 'DATE':
                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¾ãŸã¯æ•°å€¤å½¢å¼ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                    df[en_col] = df[en_col].apply(lambda x: convert_date_format(x, 'DATE') if pd.notna(x) and x != '' else '')
                elif data_type == 'DATETIME':
                    df[en_col] = df[en_col].apply(lambda x: convert_date_format(x, 'DATETIME') if pd.notna(x) and x != '' else '')

        # CSVå‡ºåŠ›
        csv_buffer = io.BytesIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8')
        csv_buffer.seek(0)

        # proceed/ ã«ä¿å­˜
        proceed_path = f"proceed/{yyyymm}/{table_name}.csv"
        proceed_blob = bucket.blob(proceed_path)
        proceed_blob.upload_from_file(csv_buffer, content_type='text/csv')

        print(f"   å‡ºåŠ›: gs://{LANDING_BUCKET}/{proceed_path}")
        print(f"âœ… å¤‰æ›å®Œäº†: {table_name}")

        return True

    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
        import traceback
        traceback.print_exc()
        return False

def load_csv_to_bigquery(bq_client, table_name, yyyymm):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’BigQueryã«ãƒ­ãƒ¼ãƒ‰"""
    table_id = f"{PROJECT_ID}.{DATASET_ID}.{table_name}"
    gcs_uri = f"gs://{LANDING_BUCKET}/proceed/{yyyymm}/{table_name}.csv"

    try:
        job_config = bigquery.LoadJobConfig(
            source_format=bigquery.SourceFormat.CSV,
            skip_leading_rows=1,
            autodetect=False,
            write_disposition=bigquery.WriteDisposition.WRITE_APPEND,
            schema_update_options=[
                bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION,
            ],
            allow_quoted_newlines=True,
            allow_jagged_rows=False,
            ignore_unknown_values=False,
            max_bad_records=0,
        )

        load_job = bq_client.load_table_from_uri(
            gcs_uri,
            table_id,
            job_config=job_config
        )

        print(f"   â³ ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {table_name} (Job ID: {load_job.job_id})")

        load_job.result(timeout=300)

        destination_table = bq_client.get_table(table_id)
        print(f"   âœ… ãƒ­ãƒ¼ãƒ‰å®Œäº†: {load_job.output_rows} è¡Œã‚’è¿½åŠ ")
        print(f"      ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {destination_table.num_rows:,} è¡Œ")

        return True

    except Exception as e:
        print(f"   âŒ ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    yyyymm = "202509"
    table_name = "profit_plan_term"

    print("=" * 60)
    print(f"profit_plan_term ETLå‡¦ç†é–‹å§‹")
    print(f"å¯¾è±¡å¹´æœˆ: {yyyymm}")
    print("=" * 60)

    storage_client = storage.Client()
    bq_client = bigquery.Client(project=PROJECT_ID)

    # 1. Excel â†’ CSVå¤‰æ›
    print("\n[1/2] Excel â†’ CSV å¤‰æ›ä¸­...")
    if not transform_excel_to_csv(storage_client, table_name, yyyymm):
        print("âŒ å¤‰æ›å¤±æ•—")
        return False

    # 2. BigQueryãƒ­ãƒ¼ãƒ‰
    print("\n[2/2] CSV â†’ BigQuery ãƒ­ãƒ¼ãƒ‰ä¸­...")
    if not load_csv_to_bigquery(bq_client, table_name, yyyymm):
        print("âŒ ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
        return False

    print("\n" + "=" * 60)
    print("âœ… profit_plan_term ETLå‡¦ç†å®Œäº†")
    print("=" * 60)

    return True

if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)
