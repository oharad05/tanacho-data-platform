#!/usr/bin/env python3
"""
raw/ â†’ proceed/ å¤‰æ›å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Excel(.xlsx)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVã«å¤‰æ›ã—ã€ã‚«ãƒ©ãƒ åã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦
BigQueryé€£æºç”¨ã®ãƒ‡ãƒ¼ã‚¿ã«æ•´å½¢ã™ã‚‹
"""

import os
import io
import re
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Optional, Any
from google.cloud import storage
from pathlib import Path

# å›ºå®šå€¤è¨­å®š
PROJECT_ID = "data-platform-prod-475201"
LANDING_BUCKET = "data-platform-landing-prod"
COLUMNS_PATH = "config/columns"  # ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚«ãƒ©ãƒ å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
MONETARY_SCALE_FILE = "config/mapping/monetary_scale_conversion.csv"  # é‡‘é¡å¤‰æ›è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
FILE_NAME_MAPPING_FILE = "config/mapping/mapping_files.csv"  # ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«

def load_column_mapping(table_name: str) -> Dict[str, Dict[str, str]]:
    """
    ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©ã‚’èª­ã¿è¾¼ã¿

    Args:
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆä¾‹: sales_target_and_achievementsï¼‰

    Returns:
        {æ—¥æœ¬èªã‚«ãƒ©ãƒ å: {"en_name": è‹±èªå, "type": ãƒ‡ãƒ¼ã‚¿å‹}}
    """
    mapping_file = f"{COLUMNS_PATH}/{table_name}.csv"
    if not os.path.exists(mapping_file):
        print(f"âš ï¸  ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {mapping_file}")
        return {}

    df = pd.read_csv(mapping_file)
    mapping = {}
    for _, row in df.iterrows():
        mapping[row['jp_name']] = {
            'en_name': row['en_name'],
            'type': row['type']
        }
    return mapping

def load_file_name_mapping() -> Dict[str, tuple]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©ã‚’èª­ã¿è¾¼ã¿

    Returns:
        {è‹±èªãƒ†ãƒ¼ãƒ–ãƒ«å: (æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«å, ã‚·ãƒ¼ãƒˆå)}
    """
    if not os.path.exists(FILE_NAME_MAPPING_FILE):
        print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {FILE_NAME_MAPPING_FILE}")
        return {}

    df = pd.read_csv(FILE_NAME_MAPPING_FILE)
    mapping = {}
    for _, row in df.iterrows():
        en_name = row['en_name']
        jp_name = row['jp_name']
        sheet_name = row['sheet_name'] if pd.notna(row['sheet_name']) else None
        mapping[en_name] = (jp_name, sheet_name)
    return mapping

def convert_date_format(value: Any, date_type: str, column_name: str = '') -> str:
    """
    æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›
    
    Args:
        value: å¤‰æ›å¯¾è±¡ã®å€¤
        date_type: DATE or DATETIME
        column_name: ã‚«ãƒ©ãƒ åï¼ˆç‰¹æ®Šå‡¦ç†ç”¨ï¼‰
    
    Returns:
        å¤‰æ›å¾Œã®æ—¥ä»˜æ–‡å­—åˆ—
    """
    if pd.isna(value) or value == '' or value is None:
        return ''
    
    # æ•°å€¤ã®å ´åˆã®å‡¦ç†
    if isinstance(value, (int, float)):
        # Excelã®ã‚·ãƒªã‚¢ãƒ«æ—¥ä»˜ã®å ´åˆï¼ˆ1900å¹´1æœˆ1æ—¥ã‹ã‚‰ã®æ—¥æ•°ï¼‰
        if value > 0 and value < 100000:
            try:
                # Excelæ—¥ä»˜ã®èµ·ç‚¹ã¯1899-12-30
                excel_base = pd.Timestamp('1899-12-30')
                dt = excel_base + pd.Timedelta(days=int(value))
                if date_type == 'DATETIME':
                    return dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                pass
        
        # Unixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆãƒŠãƒç§’ï¼‰ã®å ´åˆ
        elif value > 1e15:
            try:
                # ãƒŠãƒç§’ã‚’Datetimeã«å¤‰æ›
                dt = pd.to_datetime(value, unit='ns')
                if date_type == 'DATETIME':
                    return dt.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    return dt.strftime('%Y-%m-%d')
            except:
                pass
    
    # æ–‡å­—åˆ—ã«å¤‰æ›
    value_str = str(value)
    
    # internal_interestã®å¹´æœˆã‚«ãƒ©ãƒ ç‰¹æ®Šå‡¦ç†ï¼ˆä¾‹: "2025å¹´9æœˆ" â†’ "2025-09-01"ï¼‰
    if column_name == 'å¹´æœˆ' and 'å¹´' in value_str and 'æœˆ' in value_str:
        try:
            # "2025å¹´9æœˆ" ã®ã‚ˆã†ãªå½¢å¼ã‹ã‚‰å¹´æœˆã‚’æŠ½å‡º
            match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ', value_str)
            if match:
                year = match.group(1)
                month = match.group(2).zfill(2)
                return f"{year}-{month}-01"
        except:
            pass
    
    # profit_plan_termã®æœŸé–“ã‚«ãƒ©ãƒ ç‰¹æ®Šå‡¦ç†ï¼ˆåŒæ§˜ï¼‰
    if column_name == 'æœŸé–“' and 'å¹´' in value_str and 'æœˆ' in value_str:
        try:
            match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ', value_str)
            if match:
                year = match.group(1)
                month = match.group(2).zfill(2)
                return f"{year}-{month}-01"
        except:
            pass
    
    # DATEå‹ã®å‡¦ç†
    if date_type == 'DATE':
        # YYYY/MMå½¢å¼ã®å ´åˆã€1æ—¥ã‚’è¿½åŠ 
        if re.match(r'^\d{4}/\d{1,2}$', value_str):
            try:
                dt = pd.to_datetime(value_str + '/01', format='%Y/%m/%d')
                return dt.strftime('%Y-%m-%d')
            except:
                pass
        
        # ãã®ä»–ã®æ—¥ä»˜å½¢å¼
        try:
            dt = pd.to_datetime(value_str)
            return dt.strftime('%Y-%m-%d')
        except:
            print(f"âš ï¸  æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {value_str}")
            return value_str
    
    # DATETIMEå‹ã®å‡¦ç†
    elif date_type == 'DATETIME':
        try:
            dt = pd.to_datetime(value_str)
            return dt.strftime('%Y-%m-%d %H:%M:%S')
        except:
            print(f"âš ï¸  æ—¥æ™‚å¤‰æ›ã‚¨ãƒ©ãƒ¼: {value_str}")
            return value_str
    
    return value_str

def apply_data_type_conversion(df: pd.DataFrame, column_mapping: Dict) -> pd.DataFrame:
    """
    ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã‚’é©ç”¨
    
    Args:
        df: å¤‰æ›å¯¾è±¡ã®DataFrame
        column_mapping: ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©
    
    Returns:
        å‹å¤‰æ›å¾Œã®DataFrame
    """
    df = df.copy()
    
    for col in df.columns:
        if col not in column_mapping:
            continue
        
        data_type = column_mapping[col]['type']
        
        # DATE/DATETIMEå‹
        if data_type in ['DATE', 'DATETIME']:
            # datetime64å‹ã®å ´åˆã¯ç›´æ¥å¤‰æ›
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                if data_type == 'DATE':
                    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')
                else:
                    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d %H:%M:%S')
            else:
                df[col] = df[col].apply(lambda x: convert_date_format(x, data_type, col))
        
        # INT64å‹
        elif data_type == 'INT64':
            # ç©ºæ–‡å­—ã‚„NaNã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«nullable integerã‚’ä½¿ç”¨
            df[col] = pd.to_numeric(df[col], errors='coerce')
            # æµ®å‹•å°æ•°ç‚¹æ•°ã‚’ä¸¸ã‚ã¦ã‹ã‚‰æ•´æ•°ã«å¤‰æ›
            df[col] = df[col].round().astype('Int64')
        
        # NUMERICå‹
        elif data_type == 'NUMERIC':
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # STRINGå‹
        elif data_type == 'STRING':
            df[col] = df[col].fillna('')
            df[col] = df[col].astype(str)
            # 'nan'æ–‡å­—åˆ—ã‚’ç©ºæ–‡å­—ã«ç½®æ›
            df[col] = df[col].replace('nan', '')
    
    return df

def rename_columns(df: pd.DataFrame, column_mapping: Dict) -> pd.DataFrame:
    """
    ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã‹ã‚‰è‹±èªã«å¤‰æ›

    Args:
        df: å¤‰æ›å¯¾è±¡ã®DataFrame
        column_mapping: ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©

    Returns:
        ã‚«ãƒ©ãƒ åå¤‰æ›å¾Œã®DataFrame
    """
    rename_dict = {}

    for jp_col in df.columns:
        if jp_col in column_mapping:
            en_col = column_mapping[jp_col]['en_name']
            rename_dict[jp_col] = en_col
        else:
            print(f"âš ï¸  ãƒãƒƒãƒ”ãƒ³ã‚°æœªå®šç¾©ã®ã‚«ãƒ©ãƒ : {jp_col}")
            # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒãªã„å ´åˆã¯å…ƒã®åå‰ã‚’ä¿æŒ
            rename_dict[jp_col] = jp_col

    return df.rename(columns=rename_dict)

def load_monetary_scale_config() -> pd.DataFrame:
    """é‡‘é¡å˜ä½å¤‰æ›è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(MONETARY_SCALE_FILE):
        print(f"âš ï¸  é‡‘é¡å¤‰æ›è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MONETARY_SCALE_FILE}")
        return pd.DataFrame()

    try:
        df = pd.read_csv(MONETARY_SCALE_FILE)
        return df
    except Exception as e:
        print(f"âš ï¸  é‡‘é¡å¤‰æ›è¨­å®šã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def apply_monetary_scale_conversion(df: pd.DataFrame, table_name: str) -> pd.DataFrame:
    """
    é‡‘é¡å˜ä½å¤‰æ›ã‚’é©ç”¨

    Args:
        df: å¤‰æ›å¯¾è±¡ã®DataFrameï¼ˆè‹±èªã‚«ãƒ©ãƒ åã«å¤‰æ›æ¸ˆã¿ï¼‰
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å

    Returns:
        å¤‰æ›å¾Œã®DataFrame
    """
    try:
        # é‡‘é¡å¤‰æ›è¨­å®šã‚’èª­ã¿è¾¼ã¿
        config_df = load_monetary_scale_config()

        if config_df.empty:
            return df

        # å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¨­å®šã‚’å–å¾—
        target_config = config_df[config_df['file_name'] == table_name]

        if target_config.empty:
            print(f"   é‡‘é¡å¤‰æ›è¨­å®šãªã—: {table_name}")
            return df

        df = df.copy()

        for _, config in target_config.iterrows():
            condition_col = config['condition_column_name']
            condition_values = eval(config['condition_column_value'])  # ãƒªã‚¹ãƒˆæ–‡å­—åˆ—ã‚’è©•ä¾¡
            object_columns = eval(config['object_column_name'])  # ãƒªã‚¹ãƒˆæ–‡å­—åˆ—ã‚’è©•ä¾¡
            convert_value = float(config['convert_value'])

            # æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿
            if condition_col not in df.columns:
                print(f"âš ï¸  æ¡ä»¶ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {condition_col}")
                continue

            mask = df[condition_col].isin(condition_values)

            # å¯¾è±¡ã‚«ãƒ©ãƒ ã‚’å¤‰æ›
            for col in object_columns:
                if col in df.columns:
                    # æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è¡Œã®ã¿å¤‰æ›
                    df.loc[mask, col] = pd.to_numeric(df.loc[mask, col], errors='coerce') * convert_value
                    print(f"   ğŸ’° {col} ã‚’{convert_value}å€ã«å¤‰æ›ï¼ˆæ¡ä»¶: {condition_col} in {condition_values}ï¼‰")
                else:
                    print(f"âš ï¸  å¤‰æ›å¯¾è±¡ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {col}")

        return df

    except Exception as e:
        print(f"âš ï¸  é‡‘é¡å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return df

def transform_excel_to_csv(
    input_path: str,
    output_path: str,
    table_name: str,
    sheet_name: Optional[str] = None
) -> bool:
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§CSVã«å¤‰æ›
    
    Args:
        input_path: å…¥åŠ›Excelãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_path: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
        sheet_name: ã‚·ãƒ¼ãƒˆåï¼ˆçœç•¥æ™‚ã¯æœ€åˆã®ã‚·ãƒ¼ãƒˆï¼‰
    
    Returns:
        æˆåŠŸæ™‚True
    """
    try:
        print(f"\nğŸ“„ å‡¦ç†ä¸­: {table_name}")
        print(f"   å…¥åŠ›: {input_path}")
        
        # ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿
        column_mapping = load_column_mapping(table_name)
        if not column_mapping:
            print(f"âŒ ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_name}")
            return False
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        if sheet_name:
            df = pd.read_excel(input_path, sheet_name=sheet_name)
        else:
            # sheet_nameã‚’æŒ‡å®šã—ãªã„å ´åˆã€æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
            df = pd.read_excel(input_path)
        
        # DataFrameãŒè¾æ›¸ã¨ã—ã¦è¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if isinstance(df, dict):
            # æœ€åˆã®ã‚·ãƒ¼ãƒˆã‚’å–å¾—
            df = list(df.values())[0]
        
        # ã‚«ãƒ©ãƒ åã®æ”¹è¡Œã‚’é™¤å»
        df.columns = [col.replace('\n', '') if isinstance(col, str) else col for col in df.columns]
        
        print(f"   ãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
        
        # æ—¥æœ¬èªã‚«ãƒ©ãƒ åã‚’è‹±èªã«å¤‰æ›ï¼ˆå‹å¤‰æ›å‰ã«å®Ÿæ–½ï¼‰
        jp_column_mapping = {jp: info for jp, info in column_mapping.items()}
        
        # æ—¥ä»˜åˆ—ã®äº‹å‰å‡¦ç†ï¼ˆdatetime64å‹ã®å‡¦ç†ï¼‰
        for jp_col, info in jp_column_mapping.items():
            if jp_col in df.columns and info['type'] in ['DATE', 'DATETIME']:
                if pd.api.types.is_datetime64_any_dtype(df[jp_col]):
                    if info['type'] == 'DATE':
                        df[jp_col] = df[jp_col].dt.strftime('%Y-%m-%d')
                    else:
                        df[jp_col] = df[jp_col].dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
        df = apply_data_type_conversion(df, jp_column_mapping)

        # ã‚«ãƒ©ãƒ åå¤‰æ›
        df = rename_columns(df, jp_column_mapping)

        # é‡‘é¡å˜ä½å¤‰æ›ï¼ˆã‚«ãƒ©ãƒ åå¤‰æ›å¾Œã«å®Ÿè¡Œï¼‰
        df = apply_monetary_scale_conversion(df, table_name)

        # CSVå‡ºåŠ›
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"   å‡ºåŠ›: {output_path}")
        print(f"âœ… å¤‰æ›å®Œäº†: {table_name}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
        import traceback
        traceback.print_exc()
        return False

def process_gcs_files(yyyymm: str):
    """
    GCSä¸Šã®raw/ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã—ã¦proceed/ã«ä¿å­˜

    Args:
        yyyymm: å¯¾è±¡å¹´æœˆï¼ˆä¾‹: 202509ï¼‰
    """
    print("=" * 60)
    print(f"raw/ â†’ proceed/ å¤‰æ›å‡¦ç†")
    print(f"å¯¾è±¡å¹´æœˆ: {yyyymm}")
    print(f"ãƒã‚±ãƒƒãƒˆ: {LANDING_BUCKET}")
    print("=" * 60)

    # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = storage.Client()
    bucket = client.bucket(LANDING_BUCKET)

    # ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿
    file_name_mapping = load_file_name_mapping()

    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒªã‚¹ãƒˆï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
    tables = [
        "sales_target_and_achievements",
        "billing_balance",
        "ledger_income",
        "department_summary",
        "internal_interest",
        "profit_plan_term",
        "profit_plan_term_nagasaki",
        "profit_plan_term_fukuoka",
        "ledger_loss",
        "stocks",
        "ms_allocation_ratio",
        "customer_sales_target_and_achievements",
        "construction_progress_days_amount",
        "construction_progress_days_final_date",
    ]

    success_count = 0
    error_count = 0

    for table_name in tables:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰ã‚·ãƒ¼ãƒˆåã‚’å–å¾—
            sheet_name = None
            if table_name in file_name_mapping:
                _, sheet_name = file_name_mapping[table_name]

            # GCSãƒ‘ã‚¹ï¼ˆè‹±èªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ - sync_drive_to_gcs.pyãŒè‹±èªã‚¹ãƒ©ã‚°ã§ä¿å­˜ã™ã‚‹ãŸã‚ï¼‰
            raw_path = f"raw/{yyyymm}/{table_name}.xlsx"
            proceed_path = f"proceed/{yyyymm}/{table_name}.csv"

            # rawãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            raw_blob = bucket.blob(raw_path)
            if not raw_blob.exists():
                print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: gs://{LANDING_BUCKET}/{raw_path}")
                error_count += 1
                continue

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            temp_excel = f"/tmp/{table_name}.xlsx"
            temp_csv = f"/tmp/{table_name}.csv"

            raw_blob.download_to_filename(temp_excel)

            # å¤‰æ›å‡¦ç†
            if transform_excel_to_csv(temp_excel, temp_csv, table_name, sheet_name):
                # proceedã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                proceed_blob = bucket.blob(proceed_path)
                proceed_blob.upload_from_filename(temp_csv)
                print(f"   â†’ gs://{LANDING_BUCKET}/{proceed_path}")
                success_count += 1

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.remove(temp_excel)
                os.remove(temp_csv)
            else:
                error_count += 1

        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
            error_count += 1

    print("=" * 60)
    print(f"å‡¦ç†å®Œäº†: æˆåŠŸ {success_count} / ã‚¨ãƒ©ãƒ¼ {error_count}")
    print("=" * 60)

def generate_month_range(start_yyyymm: str, end_yyyymm: str):
    """
    é–‹å§‹æœˆã‹ã‚‰çµ‚äº†æœˆã¾ã§ã®å¹´æœˆãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ

    Args:
        start_yyyymm: é–‹å§‹å¹´æœˆ (ä¾‹: '202409')
        end_yyyymm: çµ‚äº†å¹´æœˆ (ä¾‹: '202509')

    Returns:
        å¹´æœˆãƒªã‚¹ãƒˆ ['202409', '202410', ..., '202509']
    """
    from datetime import datetime
    from dateutil.relativedelta import relativedelta

    start = datetime.strptime(start_yyyymm, '%Y%m')
    end = datetime.strptime(end_yyyymm, '%Y%m')

    months = []
    current = start
    while current <= end:
        months.append(current.strftime('%Y%m'))
        current += relativedelta(months=1)

    return months

def process_multiple_months(start_yyyymm: str, end_yyyymm: str):
    """
    è¤‡æ•°æœˆã®raw â†’ proceedå¤‰æ›ã‚’ä¸€æ‹¬å®Ÿè¡Œ

    Args:
        start_yyyymm: é–‹å§‹å¹´æœˆ
        end_yyyymm: çµ‚äº†å¹´æœˆ

    Returns:
        å‡¦ç†çµæœ {"success": æˆåŠŸæ•°, "error": ã‚¨ãƒ©ãƒ¼æ•°}
    """
    months = generate_month_range(start_yyyymm, end_yyyymm)

    print("=" * 80)
    print(f"è¤‡æ•°æœˆä¸€æ‹¬å¤‰æ›å‡¦ç†")
    print(f"å¯¾è±¡æœŸé–“: {start_yyyymm} ï½ {end_yyyymm} ({len(months)}ãƒ¶æœˆ)")
    print("=" * 80)

    total_success = 0
    total_error = 0

    for yyyymm in months:
        print(f"\n{'='*80}")
        print(f"ğŸ“… å‡¦ç†æœˆ: {yyyymm}")
        print(f"{'='*80}")

        try:
            process_gcs_files(yyyymm)
            total_success += 1
        except Exception as e:
            print(f"âŒ {yyyymm} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            total_error += 1

    print("\n" + "=" * 80)
    print(f"å…¨ä½“çµæœ: æˆåŠŸ {total_success}ãƒ¶æœˆ / ã‚¨ãƒ©ãƒ¼ {total_error}ãƒ¶æœˆ")
    print("=" * 80)

    return {"success": total_success, "error": total_error}

def process_local_files(yyyymm: str):
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›

    Args:
        yyyymm: å¯¾è±¡å¹´æœˆ
    """
    print("=" * 60)
    print(f"ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ›ãƒ†ã‚¹ãƒˆ")
    print(f"å¯¾è±¡å¹´æœˆ: {yyyymm}")
    print("=" * 60)

    # ãƒ†ã‚¹ãƒˆç”¨ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    if os.path.exists("/tmp/sample.xlsx"):
        output_path = "/tmp/sample_proceed.csv"
        if transform_excel_to_csv(
            "/tmp/sample.xlsx",
            output_path,
            "sales_target_and_achievements"
        ):
            # çµæœç¢ºèª
            df = pd.read_csv(output_path)
            print("\nå¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
            print(f"ã‚«ãƒ©ãƒ : {list(df.columns)[:5]}...")
            print(f"ãƒ‡ãƒ¼ã‚¿å‹: {df.dtypes.head()}")
            print(f"æœ€åˆã®è¡Œ: {df.iloc[0].to_dict() if len(df) > 0 else 'No data'}")

if __name__ == "__main__":
    import sys

    if len(sys.argv) >= 3 and sys.argv[1] != "--local":
        # è¤‡æ•°æœˆãƒ¢ãƒ¼ãƒ‰: python transform_raw_to_proceed.py 202409 202509
        start_yyyymm = sys.argv[1]
        end_yyyymm = sys.argv[2]
        process_multiple_months(start_yyyymm, end_yyyymm)
    elif len(sys.argv) >= 2 and sys.argv[1] != "--local":
        # å˜æœˆãƒ¢ãƒ¼ãƒ‰: python transform_raw_to_proceed.py 202509
        yyyymm = sys.argv[1]
        process_gcs_files(yyyymm)
    elif len(sys.argv) > 2 and sys.argv[2] == "--local":
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        yyyymm = sys.argv[1] if len(sys.argv) > 1 else "202509"
        process_local_files(yyyymm)
    else:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  å˜æœˆå‡¦ç†: python transform_raw_to_proceed.py 202509")
        print("  è¤‡æ•°æœˆå‡¦ç†: python transform_raw_to_proceed.py 202409 202509")
        print("  ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ: python transform_raw_to_proceed.py 202509 --local")