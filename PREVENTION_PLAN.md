# ãƒ‡ãƒ¼ã‚¿é‡è¤‡å•é¡Œã®å†ç™ºé˜²æ­¢ç­–

## ç™ºç”Ÿã—ãŸå•é¡Œã®è¦ç´„
- ETLå‡¦ç†ãŒAPPENDãƒ¢ãƒ¼ãƒ‰ã§ç¹°ã‚Šè¿”ã—å®Ÿè¡Œã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ãŒé‡è¤‡è“„ç©
- profit_plan_term: 1,300,728è¡Œï¼ˆæ­£: 72è¡Œã€ç´„6,022å€ï¼‰
- ledger_income: 621,201è¡Œï¼ˆæ­£: 21è¡Œã€ç´„1,409ï½8,453å€ï¼‰
- billing_balance: 2,474,104è¡Œï¼ˆæ­£: 340è¡Œã€ç´„67ï½244å€ï¼‰
- ledger_loss: 76,380è¡Œï¼ˆæ­£: 2è¡Œã€ç´„38,190å€ï¼‰

---

## å†ç™ºé˜²æ­¢ç­–ï¼ˆå„ªå…ˆåº¦é †ï¼‰

### ã€å¿…é ˆã€‘1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’REPLACEãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´

#### å¯¾å¿œå†…å®¹
`load_to_bigquery.py`ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œã‚’å¤‰æ›´

**ä¿®æ­£å‰**:
```python
def process_all_tables(yyyymm: str, replace_existing: bool = False):
```

**ä¿®æ­£å¾Œ**:
```python
def process_all_tables(yyyymm: str, replace_existing: bool = True):
```

**å½±éŸ¿ç¯„å›²**:
- å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å‡¦ç†
- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯è‡ªå‹•å‰Šé™¤ã•ã‚Œã¦ã‹ã‚‰è¿½åŠ ã•ã‚Œã‚‹

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é‡è¤‡ãŒç™ºç”Ÿã—ãªã„
- æ˜ç¤ºçš„ã«`--no-replace`ã‚’æŒ‡å®šã—ãªã„é™ã‚Šå®‰å…¨

---

### ã€å¿…é ˆã€‘2. ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å‰Šé™¤ã®å¿…é ˆåŒ–

#### å¯¾å¿œå†…å®¹
`delete_partition_data()`ã‚’å¸¸ã«å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«å¤‰æ›´

**ä¿®æ­£å‰**:
```python
if replace_existing:
    delete_partition_data(client, table_name, yyyymm)
```

**ä¿®æ­£å¾Œ**:
```python
# å¸¸ã«ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å‰Šé™¤ã‚’å®Ÿè¡Œï¼ˆå†ªç­‰æ€§ã®ç¢ºä¿ï¼‰
delete_partition_data(client, table_name, yyyymm)
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ETLå‡¦ç†ãŒä½•åº¦å®Ÿè¡Œã•ã‚Œã¦ã‚‚åŒã˜çµæœã«ãªã‚‹ï¼ˆå†ªç­‰æ€§ï¼‰
- `replace_existing`ãƒ•ãƒ©ã‚°ã®è¨­å®šãƒŸã‚¹ã«ã‚ˆã‚‹å½±éŸ¿ã‚’é˜²ã

---

### ã€å¿…é ˆã€‘3. ã‚·ãƒ¼ãƒˆæŒ‡å®šã®æ˜ç¤ºåŒ–ï¼ˆæ—¢ã«å¯¾å¿œæ¸ˆã¿ï¼‰

#### å¯¾å¿œå†…å®¹
è¤‡æ•°ã‚·ãƒ¼ãƒˆã‚’æŒã¤Excelãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€å–å¾—å¯¾è±¡ã‚·ãƒ¼ãƒˆã‚’æ˜ç¤º

**gcs_to_bq_service/main.pyï¼ˆ318-320è¡Œç›®ï¼‰**:
```python
# profit_plan_termã®å ´åˆã¯ã€Œæ±äº¬æ”¯åº—ç›®æ¨™103æœŸã€ã‚·ãƒ¼ãƒˆã®ã¿ã‚’èª­ã¿è¾¼ã‚€
if table_name == "profit_plan_term":
    df = pd.read_excel(io.BytesIO(excel_bytes), sheet_name='æ±äº¬æ”¯åº—ç›®æ¨™103æœŸ')
    print(f"   ã‚·ãƒ¼ãƒˆæŒ‡å®š: æ±äº¬æ”¯åº—ç›®æ¨™103æœŸ")
else:
    df = pd.read_excel(io.BytesIO(excel_bytes))
```

**æ‹¡å¼µææ¡ˆ**:
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚·ãƒ¼ãƒˆåã‚’ç®¡ç†

```python
# config/sheet_names.yaml
profit_plan_term:
  target_sheet: "æ±äº¬æ”¯åº—ç›®æ¨™103æœŸ"
  description: "æ±äº¬æ”¯åº—ã®ã¿ã‚’å¯¾è±¡"

# ã‚‚ã—ãã¯ config/sheet_names.json
{
  "profit_plan_term": {
    "target_sheet": "æ±äº¬æ”¯åº—ç›®æ¨™103æœŸ",
    "description": "æ±äº¬æ”¯åº—ã®ã¿ã‚’å¯¾è±¡"
  }
}
```

---

### ã€æ¨å¥¨ã€‘4. ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã®æ¤œè¨¼æ©Ÿèƒ½è¿½åŠ 

#### å¯¾å¿œå†…å®¹
ãƒ­ãƒ¼ãƒ‰å‰å¾Œã§ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’æ¤œè¨¼ã—ã€ç•°å¸¸å€¤ã‚’æ¤œçŸ¥

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«: validate_data_counts.py**:
```python
#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ä»¶æ•°æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
from google.cloud import bigquery, storage
import io
import pandas as pd

# æœŸå¾…å€¤ã®å®šç¾©ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ã”ã¨ã®æ­£å¸¸ç¯„å›²ï¼‰
EXPECTED_COUNTS = {
    "profit_plan_term": {"min": 50, "max": 100},
    "ledger_income": {"min": 10, "max": 100},
    "billing_balance": {"min": 200, "max": 500},
    "ledger_loss": {"min": 1, "max": 50},
    "sales_target_and_achievements": {"min": 100, "max": 10000},
    "department_summary": {"min": 50, "max": 1000},
    "internal_interest": {"min": 10, "max": 100},
}

def validate_load(table_name, yyyymm, loaded_rows):
    """ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè¡Œæ•°ã‚’æ¤œè¨¼"""
    expected = EXPECTED_COUNTS.get(table_name, {})
    min_rows = expected.get("min", 0)
    max_rows = expected.get("max", float('inf'))

    if loaded_rows < min_rows:
        print(f"âš ï¸  WARNING: {table_name} ã®ãƒ­ãƒ¼ãƒ‰è¡Œæ•°ãŒå°‘ãªã™ãã¾ã™: {loaded_rows}è¡Œ (æœŸå¾…: {min_rows}ï½{max_rows}è¡Œ)")
        return False
    elif loaded_rows > max_rows:
        print(f"âŒ ERROR: {table_name} ã®ãƒ­ãƒ¼ãƒ‰è¡Œæ•°ãŒå¤šã™ãã¾ã™: {loaded_rows}è¡Œ (æœŸå¾…: {min_rows}ï½{max_rows}è¡Œ)")
        return False
    else:
        print(f"âœ… {table_name}: {loaded_rows}è¡Œ (æ­£å¸¸ç¯„å›²)")
        return True

def validate_total_rows(client, table_name, yyyymm):
    """BigQueryãƒ†ãƒ¼ãƒ–ãƒ«ã®ç·è¡Œæ•°ã‚’æ¤œè¨¼"""
    table_id = f"data-platform-prod-475201.corporate_data.{table_name}"

    try:
        table = client.get_table(table_id)
        total_rows = table.num_rows

        # æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€æœŸå¾…å€¤ã‚’èª¿æ•´
        expected = EXPECTED_COUNTS.get(table_name, {})
        max_total = expected.get("max", 1000) * 50  # æœ€å¤§50ãƒ¶æœˆåˆ†ã‚’è¨±å®¹

        if total_rows > max_total:
            print(f"âŒ ERROR: {table_name} ã®ç·è¡Œæ•°ãŒç•°å¸¸ã«å¤šã„ã§ã™: {total_rows:,}è¡Œ")
            return False
        else:
            print(f"âœ… {table_name} ç·è¡Œæ•°: {total_rows:,}è¡Œ")
            return True
    except Exception as e:
        print(f"âš ï¸  {table_name} ã®æ¤œè¨¼ã«å¤±æ•—: {e}")
        return True  # æ¤œè¨¼å¤±æ•—ã§ã‚‚ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã¯ç¶šè¡Œ
```

**load_to_bigquery.pyã«çµ±åˆ**:
```python
# ãƒ­ãƒ¼ãƒ‰å¾Œã«æ¤œè¨¼
if load_csv_to_bigquery(client, table_name, gcs_uri, yyyymm):
    # ãƒ‡ãƒ¼ã‚¿ä»¶æ•°æ¤œè¨¼
    if not validate_load(table_name, yyyymm, loaded_rows):
        print(f"âš ï¸  {table_name} ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ãŒç•°å¸¸ã§ã™ã€‚ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    if not validate_total_rows(client, table_name, yyyymm):
        print(f"âŒ {table_name} ã®ç·è¡Œæ•°ãŒç•°å¸¸ã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
        sys.exit(1)
```

---

### ã€æ¨å¥¨ã€‘5. å®šæœŸç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

#### å¯¾å¿œå†…å®¹
BigQueryã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚¯ã‚¨ãƒªã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œ

**ç›£è¦–ã‚¯ã‚¨ãƒªä¾‹**:
```sql
-- ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œæ•°ç›£è¦–ï¼ˆæ¯æ—¥å®Ÿè¡Œï¼‰
SELECT
  table_name,
  row_count,
  CASE
    WHEN table_name = 'profit_plan_term' AND row_count > 500 THEN 'ALERT'
    WHEN table_name = 'ledger_income' AND row_count > 10000 THEN 'ALERT'
    WHEN table_name = 'billing_balance' AND row_count > 50000 THEN 'ALERT'
    WHEN table_name = 'ledger_loss' AND row_count > 5000 THEN 'ALERT'
    ELSE 'OK'
  END as status
FROM `data-platform-prod-475201.corporate_data.__TABLES__`
WHERE table_id IN ('profit_plan_term', 'ledger_income', 'billing_balance', 'ledger_loss')
```

**BigQuery Scheduled Queriesã§è¨­å®š**:
```bash
bq mk \
  --transfer_config \
  --project_id=data-platform-prod-475201 \
  --data_source=scheduled_query \
  --schedule='every day 09:00' \
  --display_name='Data Quality Monitor' \
  --target_dataset=monitoring \
  --params='{"query":"SELECT ...","destination_table_name_template":"data_quality_check"}'
```

**ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šï¼ˆCloud Monitoringï¼‰**:
- ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œæ•°ãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã«Slack/ãƒ¡ãƒ¼ãƒ«é€šçŸ¥
- ETLå®Ÿè¡Œå¤±æ•—æ™‚ã®é€šçŸ¥
- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æ•°ã®ç•°å¸¸å¢—åŠ æ¤œçŸ¥

---

### ã€æ¨å¥¨ã€‘6. ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼åˆ¶ç´„ã®è¿½åŠ ï¼ˆè©²å½“ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ï¼‰

#### å¯¾å¿œå†…å®¹
é‡è¤‡ã‚’è¨±ã•ãªã„ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åˆ¶ç´„ã‚’å®Ÿè£…

**ä¾‹: billing_balanceãƒ†ãƒ¼ãƒ–ãƒ«**:
```python
def deduplicate_before_load(df, unique_keys):
    """ãƒ­ãƒ¼ãƒ‰å‰ã«é‡è¤‡é™¤å»"""
    before_count = len(df)
    df = df.drop_duplicates(subset=unique_keys, keep='last')
    after_count = len(df)

    if before_count > after_count:
        print(f"âš ï¸  é‡è¤‡é™¤å»: {before_count - after_count}è¡Œã‚’å‰Šé™¤")

    return df

# billing_balanceã®å ´åˆ
unique_keys = ['sales_month', 'branch_code', 'customer_code']
df = deduplicate_before_load(df, unique_keys)
```

---

### ã€æ¨å¥¨ã€‘7. ETLå®Ÿè¡Œãƒ­ã‚°ã®è¨˜éŒ²

#### å¯¾å¿œå†…å®¹
ETLå®Ÿè¡Œå±¥æ­´ã‚’BigQueryã«è¨˜éŒ²

**æ–°è¦ãƒ†ãƒ¼ãƒ–ãƒ«: etl_execution_log**:
```sql
CREATE TABLE `data-platform-prod-475201.monitoring.etl_execution_log`
(
  execution_id STRING,
  table_name STRING,
  yyyymm STRING,
  execution_time TIMESTAMP,
  status STRING,  -- 'SUCCESS', 'FAILED', 'PARTIAL'
  rows_loaded INT64,
  rows_deleted INT64,
  total_rows_after INT64,
  error_message STRING,
  execution_duration_seconds FLOAT64
)
PARTITION BY DATE(execution_time)
CLUSTER BY table_name, yyyymm;
```

**load_to_bigquery.pyã«çµ±åˆ**:
```python
import uuid
import time

def log_etl_execution(client, table_name, yyyymm, status, rows_loaded, error=None):
    """ETLå®Ÿè¡Œãƒ­ã‚°ã‚’è¨˜éŒ²"""
    log_table = "data-platform-prod-475201.monitoring.etl_execution_log"

    row = {
        "execution_id": str(uuid.uuid4()),
        "table_name": table_name,
        "yyyymm": yyyymm,
        "execution_time": time.time(),
        "status": status,
        "rows_loaded": rows_loaded,
        "error_message": str(error) if error else None,
    }

    errors = client.insert_rows_json(log_table, [row])
    if errors:
        print(f"âš ï¸  ãƒ­ã‚°è¨˜éŒ²å¤±æ•—: {errors}")
```

---

### ã€å‚è€ƒã€‘8. MERGEï¼ˆUPSERTï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®ç§»è¡Œï¼ˆé•·æœŸçš„å¯¾å¿œï¼‰

#### å¯¾å¿œå†…å®¹
TRUNCATE & LOADãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰MERGEãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ç§»è¡Œ

**ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆTRUNCATE & LOADï¼‰**:
```python
# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
DELETE FROM table WHERE partition = '2025-09-01';
# æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
INSERT INTO table SELECT * FROM new_data;
```

**æ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆMERGEï¼‰**:
```sql
MERGE `data-platform-prod-475201.corporate_data.billing_balance` AS target
USING (
  SELECT * FROM `temp_table`
) AS source
ON target.sales_month = source.sales_month
   AND target.branch_code = source.branch_code
   AND target.customer_code = source.customer_code
WHEN MATCHED THEN
  UPDATE SET
    target.amount = source.amount,
    target.updated_at = CURRENT_TIMESTAMP()
WHEN NOT MATCHED THEN
  INSERT (sales_month, branch_code, customer_code, amount, created_at)
  VALUES (source.sales_month, source.branch_code, source.customer_code, source.amount, CURRENT_TIMESTAMP())
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- çœŸã®å†ªç­‰æ€§ã‚’å®Ÿç¾
- é‡è¤‡ãŒç™ºç”Ÿã—ãªã„
- ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°å±¥æ­´ã‚’ç®¡ç†å¯èƒ½

---

## å®Ÿè£…å„ªå…ˆé †ä½ã¨å·¥æ•°è¦‹ç©ã‚‚ã‚Š

| å„ªå…ˆåº¦ | å¯¾ç­– | å·¥æ•° | æœŸé™ç›®å®‰ |
|--------|------|------|----------|
| ğŸ”´ å¿…é ˆ | 1. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’REPLACEãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´ | 0.5h | å³æ™‚ |
| ğŸ”´ å¿…é ˆ | 2. ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å‰Šé™¤ã®å¿…é ˆåŒ– | 0.5h | å³æ™‚ |
| ğŸŸ¢ å®Œäº† | 3. ã‚·ãƒ¼ãƒˆæŒ‡å®šã®æ˜ç¤ºåŒ– | - | å®Œäº†æ¸ˆã¿ |
| ğŸŸ¡ æ¨å¥¨ | 4. ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã®æ¤œè¨¼æ©Ÿèƒ½è¿½åŠ  | 2h | 1é€±é–“ä»¥å†… |
| ğŸŸ¡ æ¨å¥¨ | 5. å®šæœŸç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š | 3h | 2é€±é–“ä»¥å†… |
| ğŸŸ¡ æ¨å¥¨ | 6. ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼åˆ¶ç´„ã®è¿½åŠ  | 2h | 2é€±é–“ä»¥å†… |
| ğŸŸ¡ æ¨å¥¨ | 7. ETLå®Ÿè¡Œãƒ­ã‚°ã®è¨˜éŒ² | 3h | 1ãƒ¶æœˆä»¥å†… |
| âšª å‚è€ƒ | 8. MERGEãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®ç§»è¡Œ | 10h | 3ãƒ¶æœˆä»¥å†… |

---

## ã¾ã¨ã‚

### å³åº§ã«å®Ÿæ–½ã™ã¹ãå¯¾ç­–ï¼ˆä»Šé€±ä¸­ï¼‰
1. âœ… **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’REPLACEãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´**
2. âœ… **ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³å‰Šé™¤ã®å¿…é ˆåŒ–**

### çŸ­æœŸçš„ã«å®Ÿæ–½ã™ã¹ãå¯¾ç­–ï¼ˆ1ï½2é€±é–“ï¼‰
3. ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã®æ¤œè¨¼æ©Ÿèƒ½è¿½åŠ 
4. å®šæœŸç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

### ä¸­é•·æœŸçš„ã«å®Ÿæ–½ã™ã¹ãå¯¾ç­–ï¼ˆ1ï½3ãƒ¶æœˆï¼‰
5. ETLå®Ÿè¡Œãƒ­ã‚°ã®è¨˜éŒ²
6. MERGEãƒ‘ã‚¿ãƒ¼ãƒ³ã¸ã®ç§»è¡Œ

ã“ã‚Œã‚‰ã®å¯¾ç­–ã«ã‚ˆã‚Šã€ä»Šå¾ŒåŒæ§˜ã®ãƒ‡ãƒ¼ã‚¿é‡è¤‡å•é¡ŒãŒç™ºç”Ÿã™ã‚‹ãƒªã‚¹ã‚¯ã‚’å¤§å¹…ã«ä½æ¸›ã§ãã¾ã™ã€‚
